RESULTS_PATH = "results"
EXP_PATH = "exp"
SIMPARAM_PATH = "simulation_parameters"


CHANNELS = ["minus", "plus"]
PROBER_SUFF = ["gamma", "beta", "expr"]
PROBER_STAT = ["theta", "read_model"]


RESULTS = expand("{path}/{file}", path = RESULTS_PATH, 
                 file = ["number_of_reads_in_real_data.txt", "time_and_memory_table.txt", "mapping_statistics_table.txt", 
                                                            # "grid_search_for_prior.txt", 
                                                              "digital_spike_in.txt",
                         "sim_boxplot.pdf", "sim2_boxplot.pdf", "scatters.pdf", "real_ROC_18S.pdf", "real_ROC_25S.pdf", "fake_ROC_18S.pdf", "fake_ROC_25S.pdf"])


REAL = "dms_real"
SIM = "dms_sim"
RSEM_SIM = "rsem_sim"
SIM2 = "dms_sim2"
FAKE = "dms_sim_fake"
SIM_SPIKE = "sim_spike"

#### Count number of reads in (-) and (+) channels after adaptors are trimmed

rule count_reads:
     input: REAL_DATA
     output: "{}/number_of_reads_in_real_data.txt".format(RESULTS_PATH)
     run:
        shell("wc -l {input[0]} | python3 -c 'print(\"(-): {{:,}}\".format(int(input().split()[0]) // 4))' > {output}")
        shell("wc -l {input[1]} | python3 -c 'print(\"(+): {{:,}}\".format(int(input().split()[0]) // 4))' >> {output}")

#### Evaluate running time and memory usage

rule time_and_memory:
     input:
        TOOLS[2], TOOLS[5],
        REAL_DATA,
        REF_FILT
     output:
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = PROBER_SUFF),
        expand("{path}/{name}.stat/{name}_{channel}.{suffix}", path = EXP_PATH, name = REAL, channel = CHANNELS, suffix = PROBER_STAT),
        expand("{path}/{name}_{channel}.bam", path = EXP_PATH, name = REAL, channel = CHANNELS),
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = ["time", "bam.time", "mem"])
     threads: 40
     shell:
        "{PROBER} estimate --time --memory --bowtie --bowtie-path {input[0]} -p {threads} --output-bam --read-length 37 --size-selection-min 21 --size-selection-max 526 "
        "{REF_FILT_NAME} {EXP_PATH}/{REAL} --reads {input[2]} {input[3]}"

rule generate_time_and_memory_table:
     input:
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = ["time", "bam.time", "mem"])
     output:
        "{}/time_and_memory_table.txt".format(RESULTS_PATH)
     shell:
        "{RESULTS_PATH}/scripts/generate_time_memory_table {EXP_PATH}/{REAL} {RESULTS[1]}"

#### Collect mapping statistics

rule extract_mapping_statistics:
     input:
        "{}/{}_{{channel}}.bam".format(EXP_PATH, REAL),
        "{}/rRNA_list.txt".format(ANNO_PATH)
     output:
        "{}/{}_{{channel}}.stats.txt".format(EXP_PATH, REAL)
     shell:
        "{RESULTS_PATH}/scripts/collectAlignStat {input[0]} {input[1]} > {output}"

rule generate_mapping_statistics_table:
     input:
        expand("{path}/{name}_{channel}.stats.txt", path = EXP_PATH, name = REAL, channel = CHANNELS)
     output:
        "{}/mapping_statistics_table.txt".format(RESULTS_PATH)
     shell:
        "{RESULTS_PATH}/scripts/generate_mapping_statistics_table {input} {output}"

#### Generating prior value grid search table

rule run_PROBer_for_grid_search:
     input:
        TOOLS[5],
        expand("{path}/{name}_{channel}.bam", path = EXP_PATH, name = REAL, channel = CHANNELS),
        REF_FILT
     output:
        "{path}/{name}_{{gamma}}_{{beta}}.logMAP".format(path = EXP_PATH, name = REAL)
     threads: 60
     shell:
        "{PROBER} estimate -p {threads} --read-length 37 --size-selection-min 21 --size-selection-max 526 " 
        "--gamma-init {wildcards.gamma} --beta-init {wildcards.beta} -q --output-logMAP " 
        "{REF_FILT_NAME} {EXP_PATH}/{REAL}_{wildcards.gamma}_{wildcards.beta} --bam {input[1]} {input[2]}"

rule generate_grid_search_table:
     input:
        expand("{path}/{name}_{gamma}_{beta}.logMAP", path = EXP_PATH, name = REAL, gamma = ["0.0001", "0.001", "0.01", "0.1"], beta = ["0.0001", "0.001", "0.01", "0.1"])
     output:
        "{}/grid_search_for_prior.txt".format(RESULTS_PATH)
     shell:
        "{RESULTS_PATH}/scripts/generate_grid_search_table {EXP_PATH}/{REAL} {output}"

#########

#########

rule bowtie_alignment_all:
     input: TOOLS[1], TOOLS[2],
            "{}/{{sample_name}}_{{channel}}_1.fq".format(DATA_PATH),
            REF_FILT, REF_SPIKE
     output: expand("{path}/{{sample_name}}_{{channel}}.{suffix}", path = EXP_PATH, suffix = ["bam", "err"])
     threads: 30
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{input[1]}/bowtie --norc -v 3 -a -m 200 -S -p {threads} {REF_SPIKE_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")
        else:
           shell("{input[1]}/bowtie --norc -v 3 -a -m 200 -S -p {threads} {REF_FILT_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")

rule run_PROBer:
     input: TOOLS[5],
            expand("{path}/{{sample_name}}_{channel}.bam", path = EXP_PATH, channel = CHANNELS),
            REF_FILT, REF_SPIKE
     output: expand("{path}/{{sample_name}}_SE.{suffix}", path = EXP_PATH, suffix = PROBER_SUFF)
     threads: 30
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{PROBER} estimate -p {threads} --read-length 37 --size-selection-min 21 --size-selection-max 526 "
                 "{REF_SPIKE_NAME} {EXP_PATH}/{wildcards.sample_name}_SE --bam {input[1]} {input[2]}")
        else:
           shell("{PROBER} estimate -p {threads} --read-length 37 --size-selection-min 21 --size-selection-max 526 "
                 "{REF_FILT_NAME} {EXP_PATH}/{wildcards.sample_name}_SE --bam {input[1]} {input[2]}")

rule run_RSEM_Spats_start_pipeline:
     input: TOOLS[4], TOOLS[6],
            expand("{path}/{{sample_name}}_{channel}.bam", path = EXP_PATH, channel = CHANNELS),
            expand("{path}/input_list_{part}.txt", path = SIMPARAM_PATH, part = ["boxplot", "spikes"]),
            REF_FILT, REF_SPIKE
     output: expand("{path}/{{sample_name}}_SE_RSEM.{suffix}", path = EXP_PATH, suffix = ["gamma", "beta"]),
             expand("{path}/{{sample_name}}_SE_RSEM_{channel}.isoforms.results", path = EXP_PATH, channel = CHANNELS)
     threads: 30
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{input[1]}/PROBer-single-batch-estimate -p {threads} --input-list {input[5]} --RSEM-path {input[0]} {REF_SPIKE_NAME} {EXP_PATH}/{wildcards.sample_name}_SE_RSEM "
                 "--bam {input[2]} {input[3]}")
        else:
           shell("{input[1]}/PROBer-single-batch-estimate -p {threads} --input-list {input[4]} --RSEM-path {input[0]} {REF_FILT_NAME} {EXP_PATH}/{wildcards.sample_name}_SE_RSEM "
                 "--bam {input[2]} {input[3]}")

rule bowtie_alignment_best_strata:
     input: TOOLS[1], TOOLS[2],
            "{}/{{sample_name}}_{{channel}}_1.fq".format(DATA_PATH),
            REF_FILT, REF_SPIKE
     output: expand("{path}/{{sample_name}}_{{channel}}_best_strata.{suffix}", path = EXP_PATH, suffix = ["bam", "err"])
     threads: 30
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{input[1]}/bowtie --norc -a -v 3 --best --strata -S -p {threads} {REF_SPIKE_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")
        else:
           shell("{input[1]}/bowtie --norc -a -v 3 --best --strata -S -p {threads} {REF_FILT_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")


rule extract_count_vector_for_Ding_method:
     input: "{}/{{sample_name}}_{{channel}}_best_strata.bam".format(EXP_PATH),
            expand("{ref_name}.grp", ref_name = [REF_FILT_NAME, REF_SPIKE_NAME])
     output: "{}/{{sample_name}}_{{channel}}_best_strata.counts".format(EXP_PATH)
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{RESULTS_PATH}/scripts/extractCountVectorsForDing {input[2]} {input[0]} {output}")
        else:
           shell("{RESULTS_PATH}/scripts/extractCountVectorsForDing {input[1]} {input[0]} {output}")

rule calculate_Ding_score:
     input: expand("{path}/{{sample_name}}_{channel}_best_strata.counts", path = EXP_PATH, channel = CHANNELS)
     output: "{}/{{sample_name}}_Ding.scores".format(EXP_PATH)
     shell: "{RESULTS_PATH}/scripts/calcDing {input} {output}"

rule bowtie_alignment_best:
     input: TOOLS[1], TOOLS[2],
            "{}/{{sample_name}}_{{channel}}_1.fq".format(DATA_PATH),
            REF_FILT, REF_SPIKE
     output: expand("{path}/{{sample_name}}_{{channel}}_best.{suffix}", path = EXP_PATH, suffix = ["bam", "err"])
     threads: 30
     run:
        if wildcards.sample_name.startswith(SIM_SPIKE):
           shell("{input[1]}/bowtie --norc -v 3 --best -S -p {threads} {REF_SPIKE_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")
        else:
           shell("{input[1]}/bowtie --norc -v 3 --best -S -p {threads} {REF_FILT_NAME} {input[2]} 2> {output[1]} | "
                 "{input[0]}/samtools view -b -S -o {output[0]} -")

rule extract_count_vector_for_Talkish_method:
     input: "{}/{{sample_name}}_{{channel}}_best.bam".format(EXP_PATH)
     output: "{}/{{sample_name}}_{{channel}}_best.counts".format(EXP_PATH)
     shell: "{RESULTS_PATH}/scripts/extractCountVectors {output} {input} all"

rule calculate_Talkish_score:
     input: expand("{path}/{{sample_name}}_{channel}_best.counts", path = EXP_PATH, channel = CHANNELS)
     output: "{}/{{sample_name}}_Talkish.scores".format(EXP_PATH)
     shell: "{RESULTS_PATH}/scripts/calcTalkish {input} {output}"

rule generate_melt_file:
     input: expand("{ref_name}.{suffix}", ref_name = REF_FILT_NAME, suffix = ["mappability", "transcripts.fa"]),
            expand("{path}/sim_ground_truth.{suffix}", path = SIMPARAM_PATH, suffix = ["expr", "beta"]),
            expand("{path}/{{sample_name}}_{last_part}", path = EXP_PATH, last_part = ["SE.beta", "SE_RSEM.beta", "Ding.scores", "Talkish.scores"])
     output: "{}/{{sample_name}}_results_melt.txt".format(EXP_PATH)
     shell: "{RESULTS_PATH}/scripts/analyzeResAC {EXP_PATH}/{wildcards.sample_name}_results plot 45 {input[2]} {input[0]} {input[1]} {input[3]} {input[4]} {input[5]} {input[6]} {input[7]}"

#### Generate box plots on simulated data sets for comparing different methods

rule generate_box_plot:
     input: "{}/dms_{{out_name}}_results_melt.txt".format(EXP_PATH)
     output: "{}/{{out_name}}_boxplot.pdf".format(RESULTS_PATH)
     shell: "{RESULTS_PATH}/scripts/genBoxPlot {input} {output}"

#### Generate scatter plots for comparing abundance estimates between PROBer and RSEM

rule bowtie_rsem_sim:
     input: TOOLS[1], TOOLS[2],
            expand("{path}/{name}.fq", path = DATA_PATH, name = RSEM_SIM),
            REF_FILT
     output: expand("{path}/{name}.{suffix}", path = EXP_PATH, name = RSEM_SIM, suffix = ["bam", "err"])
     threads: 30
     shell:
        "{input[1]}/bowtie --norc -v 3 -a -m 200 -S -p {threads} {REF_FILT_NAME} {input[2]} 2> {output[1]} | {input[0]}/samtools view -b -S -o {output[0]} -"

rule run_rsem_on_rsem_simulated_data:
     input: TOOLS[4],
            rules.bowtie_rsem_sim.output[0],
            REF_FILT
     output: expand("{path}/{name}.isoforms.results", path = EXP_PATH, name = RSEM_SIM)
     threads: 30
     shell:
        "{input[0]}/rsem-calculate-expression -p {threads} --bam --strand-specific --no-bam-output {input[1]} {REF_FILT_NAME} {EXP_PATH}/{RSEM_SIM}"

rule generate_scatter_plots:
     input: "{}/sim_ground_truth.expr".format(SIMPARAM_PATH),
            "{}/dms_sim_SE.expr".format(EXP_PATH),
            expand("{path}/dms_sim_SE_RSEM_{channel}.isoforms.results", path = EXP_PATH, channel = CHANNELS),
            rules.run_rsem_on_rsem_simulated_data.output
     output: "{}/scatters.pdf".format(RESULTS_PATH)
     shell:
        "{RESULTS_PATH}/scripts/genExprScatterPlots {input} {output}"

#### Generate digital spike-in experiment results

rule generate_digital_spike_in_results:
     input: "{}/digital_spike.beta".format(SIMPARAM_PATH),
            expand("{path}/{name}_{expr}TPM_{last_part}", path = EXP_PATH, name = SIM_SPIKE, expr = ["1e2", "1e3", "1e4", "1e5"], 
                   last_part = ["SE.beta", "SE_RSEM.beta", "Ding.scores", "Talkish.scores"])
     output: "{}/digital_spike_in.txt".format(RESULTS_PATH)
     shell: "{RESULTS_PATH}/scripts/analyzeSpikes {input[0]} {EXP_PATH}/{SIM_SPIKE} 45 {output}"

#### Generate ROC curves for real data

rule generate_ROC_for_real:
     input: "{}/sim_ground_truth.beta".format(SIMPARAM_PATH),
            expand("{path}/{name}_{method}.scores", path = EXP_PATH, name = REAL, method = ["Ding", "Talkish"]),
            ANNOTATIONS[:4]
     output: expand("{path}/real_ROC_{rna}.pdf", path = RESULTS_PATH, rna = ["18S", "25S"])
     shell: "{RESULTS_PATH}/scripts/plotROC {ANNO_PATH} 45 {input[0]} {input[1]} {input[2]} {RESULTS_PATH}/real_ROC"

#### Generate results for "fake" simulated data

rule generate_ROC_for_fake:
     input: expand("{path}/{name}_{last_part}", path = EXP_PATH, name = FAKE, last_part = ["SE.beta", "Ding.scores", "Talkish.scores"]),
            ANNOTATIONS[:4]
     output: expand("{path}/fake_ROC_{rna}.pdf", path = RESULTS_PATH, rna = ["18S", "25S"])
     shell: "{RESULTS_PATH}/scripts/plotROC {ANNO_PATH} 45 {input[0]} {input[1]} {input[2]} {RESULTS_PATH}/fake_ROC bottomright"



             
     
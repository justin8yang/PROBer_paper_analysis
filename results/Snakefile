RESULTS_PATH = "results"
EXP_PATH = "exp"


CHANNELS = ["minus", "plus"]
PROBER_SUFF = ["gamma", "beta", "expr"]
PROBER_STAT = ["theta", "read_model"]


RESULTS = expand("{path}/{file}", path = RESULTS_PATH, 
                 file = ["number_of_reads_in_real_data.txt", "time_and_memory_table.txt", "mapping_statistics_table.txt",
                         "grid_search_for_prior.txt"])


REAL = "dms_real"


#### Count number of reads in (-) and (+) channels after adaptors are trimmed

rule count_reads:
     input: REAL_DATA
     output: RESULTS[0]
     run:
        shell("wc -l {input[0]} | python3 -c 'print(\"(-): {{:,}}\".format(int(input().split()[0]) // 4))' > {output}")
        shell("wc -l {input[1]} | python3 -c 'print(\"(+): {{:,}}\".format(int(input().split()[0]) // 4))' >> {output}")

#### Evaluate running time and memory usage

rule time_and_memory:
     input:
        TOOLS[2], TOOLS[5],
        REAL_DATA,
        REF_FILT
     output:
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = PROBER_SUFF),
        expand("{path}/{name}.stat/{name}_{channel}.{suffix}", path = EXP_PATH, name = REAL, channel = CHANNELS, suffix = PROBER_STAT),
        expand("{path}/{name}_{channel}.bam", path = EXP_PATH, name = REAL, channel = CHANNELS),
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = ["time", "bam.time", "mem"])
     threads: 40
     message: "Run PROBer on the real data and measure running time and memory usage."
     run:
        shell("{PROBER} estimate --time --bowtie --bowtie-path {input[0]} -p {threads} --output-bam --read-length 37 --size-selection-min 21 --size-selection-max 526 "
              "{REF_FILT_NAME} {EXP_PATH}/{REAL} --reads {input[2]} {input[3]} & "
              "{RESULTS_PATH}/scripts/detect_peak_memory {EXP_PATH}/{REAL}")

rule generate_time_and_memory_table:
     input:
        expand("{path}/{name}.{suffix}", path = EXP_PATH, name = REAL, suffix = ["time", "bam.time", "mem"])
     output:
        RESULTS[1]
     shell:
        "{RESULTS_PATH}/scripts/generate_time_memory_table {EXP_PATH}/{REAL} {RESULTS[1]}"

#### Collect mapping statistics

rule extract_mapping_statistics:
     input:
        "{}/{}_{{channel}}.bam".format(EXP_PATH, REAL),
        "{}/rRNA_list.txt".format(ANNO_PATH)
     output:
        "{}/{}_{{channel}}.stats.txt".format(EXP_PATH, REAL)
     shell:
        "{RESULTS_PATH}/scripts/collectAlignStat {input[0]} {input[1]} > {output}"

rule generate_mapping_statistics_table:
     input:
        expand("{path}/{name}_{channel}.stats.txt", path = EXP_PATH, name = REAL, channel = CHANNELS)
     output:
        RESULTS[2]
     shell:
        "{RESULTS_PATH}/scripts/generate_mapping_statistics_table {input} {output}"

#### Generating prior value grid search table

rule run_PROBer_for_grid_search:
     input:
        TOOLS[5],
        expand("{path}/{name}_{channel}.bam", path = EXP_PATH, name = REAL, channel = CHANNELS),
        REF_FILT
     output:
        "{path}/{name}_{{gamma}}_{{beta}}.logMAP".format(path = EXP_PATH, name = REAL)
     threads: 60
     shell:
        "{PROBER} estimate -p {threads} --read-length 37 --size-selection-min 21 --size-selection-max 526 " 
        "--gamma-init {wildcards.gamma} --beta-init {wildcards.beta} -q --output-logMAP " 
        "{REF_FILT_NAME} {EXP_PATH}/{REAL}_{wildcards.gamma}_{wildcards.beta} --bam {input[1]} {input[2]}"

rule generate_grid_search_table:
     input:
        expand("{path}/{name}_{gamma}_{beta}.logMAP", path = EXP_PATH, name = REAL, gamma = ["0.0001", "0.001", "0.01", "0.1"], beta = ["0.0001", "0.001", "0.01", "0.1"])
     output:
        RESULTS[3]
     shell:
        "{RESULTS_PATH}/scripts/generate_grid_search_table {EXP_PATH}/{REAL} {output}"

